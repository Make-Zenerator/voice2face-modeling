
  

# ğŸ”Š Voice2Face-modeling

  

<img  src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=Python&logoColor=white"> <img  src="https://img.shields.io/badge/opencv-5C3EE8?style=for-the-badge&logo=opencv&logoColor=white"> <img  src="https://img.shields.io/badge/git-F05032?style=for-the-badge&logo=git&logoColor=white"> <img  src="https://img.shields.io/badge/NCP-03C75A?style=for-the-badge&logo=Naver&logoColor=white"> <img  src="https://img.shields.io/badge/Linux-FCC624?style=for-the-badge&logo=Linux&logoColor=white"> <img  src="https://img.shields.io/badge/Numpy-013243?style=for-the-badge&logo=Numpy&logoColor=white"> <img  src="https://img.shields.io/badge/Pytorch-EE4C2C?style=for-the-badge&logo=Pytorch&logoColor=white"> <img  src="https://img.shields.io/badge/Huggingface-FFD21E?style=for-the-badge&logo=Huggingface&logoColor=white">



## Project Structure

```
code
â”£ LDM
â”ƒ â”£ config
â”ƒ â”ƒ â”£ predict_template.yaml
â”ƒ â”ƒ â”£ train.yaml
â”ƒ â”ƒ â”— train_template.yaml
â”ƒ â”£ models
â”ƒ â”ƒ â”£ diffusion
â”ƒ â”ƒ â”ƒ â”— diffusion_models.py
â”ƒ â”ƒ â”£ module
â”ƒ â”ƒ â”ƒ â”£ attention.py
â”ƒ â”ƒ â”ƒ â”£ blocks.py
â”ƒ â”ƒ â”ƒ â”£ decoder.py
â”ƒ â”ƒ â”ƒ â”£ ema.py
â”ƒ â”ƒ â”ƒ â”£ encoder.py
â”ƒ â”ƒ â”ƒ â”£ noise_scheduler.py
â”ƒ â”ƒ â”ƒ â”£ voice_encoder.py
â”ƒ â”ƒ â”ƒ â”— vqvae.py
â”ƒ â”ƒ â”— utils.py
â”ƒ â”£ modules
â”ƒ â”ƒ â”£ datasets.py
â”ƒ â”ƒ â”£ earlystoppers.py
â”ƒ â”ƒ â”£ losses.py
â”ƒ â”ƒ â”£ metrics.py
â”ƒ â”ƒ â”£ optimizers.py
â”ƒ â”ƒ â”£ recoders.py
â”ƒ â”ƒ â”£ scalers.py
â”ƒ â”ƒ â”£ schedulers.py
â”ƒ â”ƒ â”£ trainer.py
â”ƒ â”ƒ â”£ utils.py
â”ƒ â”ƒ â”— vad_ex.py
â”ƒ â”£ LDM_LoRA.ipynb
â”ƒ â”£ LDM_models.py
â”ƒ â”£ LoRA_train.py
â”ƒ â”£ custom_pipeline.py
â”ƒ â”£ inference.py
â”ƒ â”£ logger.ipynb
â”ƒ â”£ logger.py
â”ƒ â”£ predict.py
â”ƒ â”£ requirements.txt
â”ƒ â”£ sf2f_encoder.py
â”ƒ â”— train.py
â”£ SimSwap
â”ƒ â”£ docs
â”ƒ â”ƒ â”£ ...
â”ƒ â”£ insightface_func
â”ƒ â”ƒ â”£ utils
â”ƒ â”ƒ â”ƒ â”— face_align_ffhqandnewarc.py
â”ƒ â”ƒ â”£ __init__.py
â”ƒ â”ƒ â”£ face_detect_crop_multi.py
â”ƒ â”ƒ â”— face_detect_crop_single.py
â”ƒ â”£ models
â”ƒ â”ƒ â”£ __init__.py
â”ƒ â”ƒ â”£ arcface_models.py
â”ƒ â”ƒ â”£ base_model.py
â”ƒ â”ƒ â”£ config.py
â”ƒ â”ƒ â”£ fs_model.py
â”ƒ â”ƒ â”£ fs_networks.py
â”ƒ â”ƒ â”£ fs_networks_512.py
â”ƒ â”ƒ â”£ fs_networks_fix.py
â”ƒ â”ƒ â”£ models.py
â”ƒ â”ƒ â”£ networks.py
â”ƒ â”ƒ â”£ pix2pixHD_model.py
â”ƒ â”ƒ â”£ projected_model.py
â”ƒ â”ƒ â”£ projectionhead.py
â”ƒ â”ƒ â”— ui_model.py
â”ƒ â”£ options
â”ƒ â”ƒ â”£ base_options.py
â”ƒ â”ƒ â”£ test_options.py
â”ƒ â”ƒ â”— train_options.py
â”ƒ â”£ parsing_model
â”ƒ â”ƒ â”£ model.py
â”ƒ â”ƒ â”— resnet.py
â”ƒ â”£ pg_modules
â”ƒ â”ƒ â”£ blocks.py
â”ƒ â”ƒ â”£ diffaug.py
â”ƒ â”ƒ â”£ projected_discriminator.py
â”ƒ â”ƒ â”— projector.py
â”ƒ â”£ simswaplogo
â”ƒ â”ƒ â”— ...
â”ƒ â”£ util
â”ƒ â”ƒ â”£ add_watermark.py
â”ƒ â”ƒ â”£ gifswap.py
â”ƒ â”ƒ â”£ html.py
â”ƒ â”ƒ â”£ image_pool.py
â”ƒ â”ƒ â”£ json_config.py
â”ƒ â”ƒ â”£ logo_class.py
â”ƒ â”ƒ â”£ norm.py
â”ƒ â”ƒ â”£ plot.py
â”ƒ â”ƒ â”£ reverse2original.py
â”ƒ â”ƒ â”£ save_heatmap.py
â”ƒ â”ƒ â”£ util.py
â”ƒ â”ƒ â”£ videoswap.py
â”ƒ â”ƒ â”£ videoswap_multispecific.py
â”ƒ â”ƒ â”£ videoswap_specific.py
â”ƒ â”ƒ â”— visualizere.py
â”ƒ â”£ cog.yaml
â”ƒ â”£ download-weights.sh
â”ƒ â”£ inference_swap.py
â”ƒ â”£ predict.py
â”ƒ â”£ test_one_image.py
â”ƒ â”£ test_video_swap_multispecific.py
â”ƒ â”£ test_video_swapmulti.py
â”ƒ â”£ test_video_swapsingle.py
â”ƒ â”£ test_video_swapspecific.py
â”ƒ â”£ test_wholeimage_swap_multispecific.py
â”ƒ â”£ test_whileimage_swapmulti.py
â”ƒ â”£ test_wholeimage_swapsingle.py
â”ƒ â”£ test_wholeimage_swapspecific.py
â”ƒ â”— train.py
â”£ pytorch_template
â”ƒ â”— ...
â”£ sf2f
â”ƒ â”£ datasets
â”ƒ â”ƒ â”£ __init__.py
â”ƒ â”ƒ â”£ build_dataset.py
â”ƒ â”ƒ â”£ build_olkavs_dataset.py
â”ƒ â”ƒ â”£ utils.py
â”ƒ â”ƒ â”— vox_dataset.py
â”ƒ â”£ images
â”ƒ â”ƒ â”— ...
â”ƒ â”£ models
â”ƒ â”ƒ â”£ __init__.py
â”ƒ â”ƒ â”£ attention.py
â”ƒ â”ƒ â”£ crn.py
â”ƒ â”ƒ â”£ discriminators.py
â”ƒ â”ƒ â”£ encoder_decoder.py
â”ƒ â”ƒ â”£ face_decoders.py
â”ƒ â”ƒ â”£ fusers.py
â”ƒ â”ƒ â”£ inception_resnet_v1.py
â”ƒ â”ƒ â”£ layers.py
â”ƒ â”ƒ â”£ model_collection.py
â”ƒ â”ƒ â”£ model_setup.py
â”ƒ â”ƒ â”£ networks.py
â”ƒ â”ƒ â”£ perceptual.py
â”ƒ â”ƒ â”— voice_encoders.py
â”ƒ â”£ options
â”ƒ â”ƒ â”£ data_opts
â”ƒ â”ƒ â”ƒ â”£ olk.yaml
â”ƒ â”ƒ â”ƒ â”— vox.yaml
â”ƒ â”ƒ â”£ vox
â”ƒ â”ƒ â”ƒ â”£ baseline
â”ƒ â”ƒ â”ƒ â”ƒ â”— v2f.yaml
â”ƒ â”ƒ â”ƒ â”— sf2f
â”ƒ â”ƒ â”ƒ â”ƒ â”£ olkavs_sf2f_1st_stage.yaml
â”ƒ â”ƒ â”ƒ â”ƒ â”£ sf2f_1st_stage.yaml
â”ƒ â”ƒ â”ƒ â”ƒ â”£ sf2f_fuser.yaml
â”ƒ â”ƒ â”ƒ â”ƒ â”£ sf2f_mid_1st_stage.yaml
â”ƒ â”ƒ â”ƒ â”ƒ â”— sf2f_mid_fuser.yaml
â”ƒ â”ƒ â”£ __init__.py
â”ƒ â”ƒ â”— opts.py
â”ƒ â”£ scripts
â”ƒ â”ƒ â”£ build_demo_set.py
â”ƒ â”ƒ â”£ compute_diversity_score.py
â”ƒ â”ƒ â”£ compute_fid_score.py
â”ƒ â”ƒ â”£ compute_inception_score.py
â”ƒ â”ƒ â”£ compute_mel_mean_var.py
â”ƒ â”ƒ â”£ compute_vggface_score.py
â”ƒ â”ƒ â”£ convert_wav_to_mel.py
â”ƒ â”ƒ â”£ create_split_json.py
â”ƒ â”ƒ â”£ download_vggface_weights.sh
â”ƒ â”ƒ â”£ install_requirements.py
â”ƒ â”ƒ â”£ print_args.py
â”ƒ â”ƒ â”£ sample_mel_spectrograms.py
â”ƒ â”ƒ â”£ strip_checkpoint.py
â”ƒ â”ƒ â”£ strip_old_args.py
â”ƒ â”ƒ â”— watch_data.py
â”ƒ â”£ utils
â”ƒ â”ƒ â”£ visualization
â”ƒ â”ƒ â”ƒ â”£ __init__.py
â”ƒ â”ƒ â”ƒ â”£ html.py
â”ƒ â”ƒ â”ƒ â”£ plot.py
â”ƒ â”ƒ â”ƒ â”£ tsne.py
â”ƒ â”ƒ â”ƒ â”— vis.py
â”ƒ â”ƒ â”£ __init__.py
â”ƒ â”ƒ â”£ bilinear.py
â”ƒ â”ƒ â”£ box_utils.py
â”ƒ â”ƒ â”£ common.py
â”ƒ â”ƒ â”£ compute_metrics.py
â”ƒ â”ƒ â”£ connect_mlflow.py
â”ƒ â”ƒ â”£ evaluate.py
â”ƒ â”ƒ â”£ evaluate_fid.py
â”ƒ â”ƒ â”£ filter_pickle.py
â”ƒ â”ƒ â”£ logger.py
â”ƒ â”ƒ â”£ losses.py
â”ƒ â”ƒ â”£ metrics.py
â”ƒ â”ƒ â”£ pgan_utils.py
â”ƒ â”ƒ â”£ s2f_evaluator.py
â”ƒ â”ƒ â”£ training_utils.py
â”ƒ â”ƒ â”£ utils.py
â”ƒ â”ƒ â”£ vad_ex.py
â”ƒ â”ƒ â”£ wandb_logger.py
â”ƒ â”ƒ â”— wav2mel.py
â”ƒ â”£ infer.py
â”ƒ â”— inference_fuser.py
â”ƒ â”£ requirements.txt
â”ƒ â”£ test.py
â”ƒ â”— train.py.py
â”— wcgan-gp
  â”£ dataset.py
  â”£ inference.py
  â”£ inference_options.py
  â”£ model.py
  â”£ train.py
  â”£ train_options.py
  â”— utils.py
â”— README.md
â”— requirements.txt
â”— train.sh
â”— voxceleb_download.sh
...
```
## Usage

  

#### LDM
 - Latent Diffusion: [paper](https://arxiv.org/abs/2112.10752) | [github](https://github.com/CompVis/latent-diffusion?tab=readme-ov-file)
 - Low-Rank Adaptation: [paper](https://arxiv.org/abs/2106.09685) | [github](https://github.com/microsoft/LoRA)
 - ê¸°ì¡´ Speech Fusion to Face ëª¨ë¸ì˜ voice encoderë¥¼ í™œìš©í•˜ì—¬ ê²°ê³¼ ì´ë¯¸ì§€ì˜ í’ˆì§ˆ í–¥ìƒì„ ìœ„í•´ Latent Diffusion modelì„ êµ¬í˜„í•œ í´ë”ì…ë‹ˆë‹¤.
 - ë˜í•œ, Diffusion modelì˜ ì›í™œí•œ í•™ìŠµì„ ìœ„í•´ LoRA êµ¬ì¡°ë¥¼ ì¶”ê°€í•˜ì˜€ê³ , ì´ë¥¼ í†µí•´ í•™ìŠµ ì‹œê°„ ë° ì„±ëŠ¥ì„ ê°œì„ í•˜ì˜€ìŠµë‹ˆë‹¤.

#### SimSwap
 - SimSwap: [paper](https://arxiv.org/pdf/2106.06340v1) | [github](https://github.com/neuralchen/SimSwap)
 - ìŒì„± ë°ì´í„°ë¡œ ë¶€í„° ìƒì„±ëœ ì–¼êµ´ì„ ê¸°ì¡´ ì˜ìƒì— í•©ì„±í•˜ê¸° ìœ„í•´ ì‚¬ìš©ëœ ëª¨ë¸ì…ë‹ˆë‹¤.
 - ìƒì„±ëœ ì •ë©´ ì–¼êµ´ì„ ì˜ìƒ ì† ë‹¤ì–‘í•œ ê°ë„ì— ë§ê²Œ í•©ì„±í•˜ê¸° ìœ„í•´ í•©ì„± ì†ë„ë³´ë‹¤ ì •í™•ë„ì™€ í’ˆì§ˆì´ ë³´ë‹¤ ë†’ì€ ëª¨ë¸ì„ ì„ íƒí•˜ì˜€ìŠµë‹ˆë‹¤.
 - í•©ì„±ì´ ì™„ë£Œëœ ì˜ìƒì„ gif í˜¹ì€ mp4 í˜•íƒœë¡œ ìƒì„±í•˜ì—¬ ì¶œë ¥í•©ë‹ˆë‹¤.

#### pytorch_template 
 - pytorch template: ì°¸ê³ [github](https://github.com/victoresque/pytorch-template)
 - ëª¨ë¸ ê°œë°œì˜ íš¨ìœ¨ì„±ê³¼ ì¼ê´€ì„±ì„ ìœ ì§€í•˜ê¸° ìœ„í•´ ì‚¬ìš©í•œ í˜•ì‹ì…ë‹ˆë‹¤.
 - ê°œë°œí•œ ëª¨ë¸ì„ íŒ€ì›ë“¤ì´ ì´í•´í•˜ê¸° ì‰½ë„ë¡ ì •ë¦¬í•˜ì—¬ ê³µìœ í•˜ì˜€ìŠµë‹ˆë‹¤.

#### sf2f
 - Speech Fusion to Face: [paper](https://arxiv.org/abs/2006.05888) | [github](https://github.com/BAI-Yeqi/SF2F_PyTorch) | [page](https://sf2f.github.io/)
 - ìŒì„± ë°ì´í„° (.wav) íŒŒì¼ì„ mel_spectrogramìœ¼ë¡œ ë³€í™˜í•œ í›„, ì´ë¥¼ í†µí•´ ì–¼êµ´ì„ ì¬ìƒì„±í•˜ëŠ” ëª¨ë¸ì…ë‹ˆë‹¤.
 - `scripts/convert_wav_to_mel.py`: ìŒì„± ë°ì´í„°(.wav) íŒŒì¼ì„ ì¼ì •í•œ í¬ê¸°(100x150)ì˜ mel_spectrogramìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ì „ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•˜ê³  ì´ë¥¼ pickle íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤.
 - `options/data_opts` : ë°ì´í„° ì…‹ì„ ìƒì„±í•  ë•Œ ì‚¬ìš©í•˜ëŠ” ë§¤ê°œ ë³€ìˆ˜ë“¤ì„ ì§€ì •í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ë“¤ì„ ì €ì¥í•´ë‘” í´ë”ë¡œ, vox celeb datasetê³¼ olkavs datasetì— ëŒ€í•œ ìŠ¤í¬ë¦½íŠ¸ê°€ ì‚¬ìš©ë©ë‹ˆë‹¤.
 - `options/sf2f`: trainê³¼ inference ì‹œì— ì‚¬ìš©ë˜ëŠ” ëª¨ë“  ë§¤ê°œ ë³€ìˆ˜ë“¤ì„ ì§€ì •í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ë“¤ì„ ì €ì¥í•´ë‘” í´ë”ë¡œ, sf2f with voxì™€ sf2f with olkavsë¡œ ë‚˜ë‰˜ì–´ì ¸ ìˆê³ , sf2fëŠ” ëª¨ë¸ì˜ ë°©ì‹ê³¼ ì´ë¯¸ì§€ ë°ì´í„°ì˜ í¬ê¸°ì— ë”°ë¼ ë¶„ë¥˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
 - `utils/compute_metrics.py`: ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ë¥¼ ìœ„í•´ ì‚¬ìš©ë˜ëŠ” metricsë¥¼ ì„ ì–¸í•˜ê³  ê³„ì‚°í•˜ëŠ” ê²ƒì„ í†µí•´ ëª¨ë¸ í•™ìŠµì˜ í‰ê°€ ì§€í‘œë¡œ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤.
 - `connect_mlflow.py`: mlflowë¥¼ í†µí•´ ëª¨ë¸ í•™ìŠµì„ ëª¨ë‹ˆí„°ë§í•˜ê³ , ìµœì ì˜ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ëª¨ë¸ì˜ weightsë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ mlflow ì„œë²„ì™€ ì—°ê²°í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤.


#### wcgan-gp
 - Wasserstein GAN: [paper](https://arxiv.org/pdf/1701.07875) | [github](https://github.com/martinarjovsky/WassersteinGAN)
 - Wasserstein GAN with Gradient Penalty: [paper](https://arxiv.org/abs/1704.00028) | [github](https://github.com/igul222/improved_wgan_training)
 - Conditional GAN: [paper](https://arxiv.org/abs/1411.1784) | [github](https://github.com/wiseodd/generative-models/blob/master/GAN/conditional_gan/cgan_tensorflow.py)
 - ë³¸ í”„ë¡œì íŠ¸ì˜ ëª©ì†Œë¦¬ë¥¼ í†µí•œ ì–¼êµ´ ìƒì„± ê²°ê³¼ ì´ë¯¸ì§€ì˜ ì‚¬ìš©ì í‰ê°€ë¥¼ ìœ„í•´ êµ¬í˜„ëœ ë¹„êµêµ°(ëª©ì†Œë¦¬x, ë‚˜ì´/ì„±ë³„o) ëª¨ë¸ì…ë‹ˆë‹¤.
 - Wasserstein GANì˜ í•™ìŠµ ì•ˆì •ì„±ì„ ë†’ì´ê¸° ìœ„í•´ gradient penaltyë¥¼ ì¶”ê°€í•˜ì˜€ê³ , ëª¨ë¸ ê²°ê³¼ë¥¼ ìœ ë„í•˜ê¸° ìœ„í•œ conditionì„ ì¶”ê°€í•˜ì˜€ìŠµë‹ˆë‹¤.
 - ëª¨ë¸ ìì²´ ì„±ëŠ¥ì´ ë¹„êµ ë¶ˆê°€ëŠ¥í•œ ìˆ˜ì¤€ìœ¼ë¡œ í•™ìŠµë˜ì–´, celebA datasetì„ í†µí•´ ì‚¬ì „í•™ìŠµì„ ì§„í–‰í•˜ê³  ì´í›„ vox celeb datasetì— finetuningì„ ì§„í–‰í•˜ì˜€ìŠµë‹ˆë‹¤.


  

## Getting Started

  
### Setting up Virtual Environment

  
1. Initialize and update the server

```

su -

source .bashrc

```

  

2. Create and Activate a virtual environment in the project directory

  

```

conda create -n env python=3.8

conda activate env

```

  

4. To deactivate and exit the virtual environment, simply run:

  

```

deactivate

```

  

### Install Requirements

  

To Install the necessary packages listed in `requirements.txt`, run the following command while your virtual environment is activated:

```

pip install -r requirements.txt

```

  
  
## Links
- [Naver BoostCamp 6th github](https://github.com/boostcampaitech6/level2-3-cv-finalproject-cv-08)
