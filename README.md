
  

# ğŸ”Š Voice2Face-modeling

  

<img  src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=Python&logoColor=white"> <img  src="https://img.shields.io/badge/opencv-5C3EE8?style=for-the-badge&logo=opencv&logoColor=white"> <img  src="https://img.shields.io/badge/git-F05032?style=for-the-badge&logo=git&logoColor=white"> <img  src="https://img.shields.io/badge/NCP-03C75A?style=for-the-badge&logo=Naver&logoColor=white"> <img  src="https://img.shields.io/badge/Linux-FCC624?style=for-the-badge&logo=Linux&logoColor=white"> <img  src="https://img.shields.io/badge/Numpy-013243?style=for-the-badge&logo=Numpy&logoColor=white"> <img  src="https://img.shields.io/badge/Pytorch-EE4C2C?style=for-the-badge&logo=Pytorch&logoColor=white"> <img  src="https://img.shields.io/badge/Huggingface-FFD21E?style=for-the-badge&logo=Huggingface&logoColor=white">



## Project Structure

```
code
â”£ LDM
â”ƒ â”— ...
â”£ SimSwap
â”ƒ â”— ...
â”£ pytorch_template
â”ƒ â”— ...
â”£ sf2f
â”ƒ â”— ...
â”— wcgan-gp
  â”— ...
â”— README.md
â”— requirements.txt
â”— train.sh
â”— voxceleb_download.sh
...
```
## Usage

  

#### LDM
 - Latent Diffusion: [paper](https://arxiv.org/abs/2112.10752) | [github](https://github.com/CompVis/latent-diffusion?tab=readme-ov-file)
 - Low-Rank Adaptation: [paper](https://arxiv.org/abs/2106.09685) | [github](https://github.com/microsoft/LoRA)
 - ê¸°ì¡´ Speech Fusion to Face ëª¨ë¸ì˜ voice encoderë¥¼ í™œìš©í•˜ì—¬ ê²°ê³¼ ì´ë¯¸ì§€ì˜ í’ˆì§ˆ í–¥ìƒì„ ìœ„í•´ Latent Diffusion modelì„ êµ¬í˜„í•œ í´ë”ì…ë‹ˆë‹¤.
 - ë˜í•œ, Diffusion modelì˜ ì›í™œí•œ í•™ìŠµì„ ìœ„í•´ LoRA êµ¬ì¡°ë¥¼ ì¶”ê°€í•˜ì˜€ê³ , ì´ë¥¼ í†µí•´ í•™ìŠµ ì‹œê°„ ë° ì„±ëŠ¥ì„ ê°œì„ í•˜ì˜€ìŠµë‹ˆë‹¤.

#### SimSwap
 - SimSwap: [paper](https://arxiv.org/pdf/2106.06340v1) | [github](https://github.com/neuralchen/SimSwap)
 - ìŒì„± ë°ì´í„°ë¡œ ë¶€í„° ìƒì„±ëœ ì–¼êµ´ì„ ê¸°ì¡´ ì˜ìƒì— í•©ì„±í•˜ê¸° ìœ„í•´ ì‚¬ìš©ëœ ëª¨ë¸ì…ë‹ˆë‹¤.
 - ìƒì„±ëœ ì •ë©´ ì–¼êµ´ì„ ì˜ìƒ ì† ë‹¤ì–‘í•œ ê°ë„ì— ë§ê²Œ í•©ì„±í•˜ê¸° ìœ„í•´ í•©ì„± ì†ë„ë³´ë‹¤ ì •í™•ë„ì™€ í’ˆì§ˆì´ ë³´ë‹¤ ë†’ì€ ëª¨ë¸ì„ ì„ íƒí•˜ì˜€ìŠµë‹ˆë‹¤.
 - í•©ì„±ì´ ì™„ë£Œëœ ì˜ìƒì„ gif í˜¹ì€ mp4 í˜•íƒœë¡œ ìƒì„±í•˜ì—¬ ì¶œë ¥í•©ë‹ˆë‹¤.

#### pytorch_template 
 - pytorch template: ì°¸ê³ [github](https://github.com/victoresque/pytorch-template)
 - ëª¨ë¸ ê°œë°œì˜ íš¨ìœ¨ì„±ê³¼ ì¼ê´€ì„±ì„ ìœ ì§€í•˜ê¸° ìœ„í•´ ì‚¬ìš©í•œ í˜•ì‹ì…ë‹ˆë‹¤.
 - ê°œë°œí•œ ëª¨ë¸ì„ íŒ€ì›ë“¤ì´ ì´í•´í•˜ê¸° ì‰½ë„ë¡ ì •ë¦¬í•˜ì—¬ ê³µìœ í•˜ì˜€ìŠµë‹ˆë‹¤.

#### sf2f
 - Speech Fusion to Face: [paper](https://arxiv.org/abs/2006.05888) | [github](https://github.com/BAI-Yeqi/SF2F_PyTorch) | [page](https://sf2f.github.io/)
 - ìŒì„± ë°ì´í„° (.wav) íŒŒì¼ì„ mel_spectrogramìœ¼ë¡œ ë³€í™˜í•œ í›„, ì´ë¥¼ í†µí•´ ì–¼êµ´ì„ ì¬ìƒì„±í•˜ëŠ” ëª¨ë¸ì…ë‹ˆë‹¤.
 - `scripts/convert_wav_to_mel.py`: ìŒì„± ë°ì´í„°(.wav) íŒŒì¼ì„ ì¼ì •í•œ í¬ê¸°(100x150)ì˜ mel_spectrogramìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ì „ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•˜ê³  ì´ë¥¼ pickle íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤.
 - `options/data_opts` : ë°ì´í„° ì…‹ì„ ìƒì„±í•  ë•Œ ì‚¬ìš©í•˜ëŠ” ë§¤ê°œ ë³€ìˆ˜ë“¤ì„ ì§€ì •í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ë“¤ì„ ì €ì¥í•´ë‘” í´ë”ë¡œ, vox celeb datasetê³¼ olkavs datasetì— ëŒ€í•œ ìŠ¤í¬ë¦½íŠ¸ê°€ ì‚¬ìš©ë©ë‹ˆë‹¤.
 - `options/sf2f`: trainê³¼ inference ì‹œì— ì‚¬ìš©ë˜ëŠ” ëª¨ë“  ë§¤ê°œ ë³€ìˆ˜ë“¤ì„ ì§€ì •í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ë“¤ì„ ì €ì¥í•´ë‘” í´ë”ë¡œ, sf2f with voxì™€ sf2f with olkavsë¡œ ë‚˜ë‰˜ì–´ì ¸ ìˆê³ , sf2fëŠ” ëª¨ë¸ì˜ ë°©ì‹ê³¼ ì´ë¯¸ì§€ ë°ì´í„°ì˜ í¬ê¸°ì— ë”°ë¼ ë¶„ë¥˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
 - `utils/compute_metrics.py`: ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ë¥¼ ìœ„í•´ ì‚¬ìš©ë˜ëŠ” metricsë¥¼ ì„ ì–¸í•˜ê³  ê³„ì‚°í•˜ëŠ” ê²ƒì„ í†µí•´ ëª¨ë¸ í•™ìŠµì˜ í‰ê°€ ì§€í‘œë¡œ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤.
 - `connect_mlflow.py`: mlflowë¥¼ í†µí•´ ëª¨ë¸ í•™ìŠµì„ ëª¨ë‹ˆí„°ë§í•˜ê³ , ìµœì ì˜ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ëª¨ë¸ì˜ weightsë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ mlflow ì„œë²„ì™€ ì—°ê²°í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤.


#### wcgan-gp
 - Wasserstein GAN: [paper](https://arxiv.org/pdf/1701.07875) | [github](https://github.com/martinarjovsky/WassersteinGAN)
 - Wasserstein GAN with Gradient Penalty: [paper](https://arxiv.org/abs/1704.00028) | [github](https://github.com/igul222/improved_wgan_training)
 - Conditional GAN: [paper](https://arxiv.org/abs/1411.1784) | [github](https://github.com/wiseodd/generative-models/blob/master/GAN/conditional_gan/cgan_tensorflow.py)
 - ë³¸ í”„ë¡œì íŠ¸ì˜ ëª©ì†Œë¦¬ë¥¼ í†µí•œ ì–¼êµ´ ìƒì„± ê²°ê³¼ ì´ë¯¸ì§€ì˜ ì‚¬ìš©ì í‰ê°€ë¥¼ ìœ„í•´ êµ¬í˜„ëœ ë¹„êµêµ°(ëª©ì†Œë¦¬x, ë‚˜ì´/ì„±ë³„o) ëª¨ë¸ì…ë‹ˆë‹¤.
 - Wasserstein GANì˜ í•™ìŠµ ì•ˆì •ì„±ì„ ë†’ì´ê¸° ìœ„í•´ gradient penaltyë¥¼ ì¶”ê°€í•˜ì˜€ê³ , ëª¨ë¸ ê²°ê³¼ë¥¼ ìœ ë„í•˜ê¸° ìœ„í•œ conditionì„ ì¶”ê°€í•˜ì˜€ìŠµë‹ˆë‹¤.
 - ëª¨ë¸ ìì²´ ì„±ëŠ¥ì´ ë¹„êµ ë¶ˆê°€ëŠ¥í•œ ìˆ˜ì¤€ìœ¼ë¡œ í•™ìŠµë˜ì–´, celebA datasetì„ í†µí•´ ì‚¬ì „í•™ìŠµì„ ì§„í–‰í•˜ê³  ì´í›„ vox celeb datasetì— finetuningì„ ì§„í–‰í•˜ì˜€ìŠµë‹ˆë‹¤.


  

## Getting Started

  
### Setting up Virtual Environment

  
1. Initialize and update the server

```

su -

source .bashrc

```

  

2. Create and Activate a virtual environment in the project directory

  

```

conda create -n env python=3.8

conda activate env

```

  

4. To deactivate and exit the virtual environment, simply run:

  

```

deactivate

```

  

### Install Requirements

  

To Install the necessary packages listed in `requirements.txt`, run the following command while your virtual environment is activated:

```

pip install -r requirements.txt

```

  
  
## Links
- [Naver BoostCamp 6th github](https://github.com/boostcampaitech6/level2-3-cv-finalproject-cv-08)
