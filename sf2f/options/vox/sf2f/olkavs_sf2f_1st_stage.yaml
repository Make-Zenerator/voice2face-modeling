# Optimal final version of encoder-decoder and Loss Function
# Encoder: Inceptional 1D CNN
# Decoder: Upsampling + CNN
logs:
  name: olkavs_sf2f_1st_stage
  output_dir: /workspace/voice2face-modeling/sf2f/output/olkavs
  run_name: sf2f_1st_stage_olk_1/50
# mlflow settings
mlflow:
  timeout: 36000
  MLFLOW_S3_ENDPOINT_URL: http://storage.makezenerator.site:9000
  MLFLOW_TRACKING_URI: http://storage.makezenerator.site:5001
  AWS_ACCESS_KEY_ID: minio
  AWS_SECRET_ACCESS_KEY: miniostorage
  experiment: sf2f_olkavs
# data-related settings
data:
  dataset: olk
  data_size: 50
  data_opts_path: /workspace/voice2face-modeling/sf2f/options/data_opts/olk.yaml
  image_size: [64, 64]
# model related settings
generator:
  arch: EncoderDecoder
  options:
    encoder_arch: V2F1DCNN
    encoder_kwargs:
      input_channel: 308
      channels: [256, 384, 576, 864]
      output_channel: 512
      normalize_embedding: True
      inception_mode: True
      segments_fusion: True
      normalize_fusion: True
      fuser_arch: AttentionFuserV1
      fuser_kwargs:
        dimensions: 512
        dim_out: 512
        attention_type: general
        ignore_tanh: True
    decoder_arch: FaceGanDecoder
    decoder_kwargs:
      noise_dim: 512
      mlp_normalization: none
      normalization: batch
      activation: leakyrelu-0.1
discriminator:
  generic:
    normalization: batch
    padding: valid
    activation: leakyrelu-0.1
  image:
    arch: 'C4-64-2,C4-128-2,C4-256-2'
  identity:
    arch: 'C4-64-2,C4-128-2,C4-256-2'
    num_id: 0 # will be updated in train.py
optim:
  # Discriminator Loss Weights
  d_loss_weight: 1.0
  d_img_weight: 1.0 #0.5
  ac_loss_weight: 0.05
  # Generator Loss Weights
  gan_loss_type: 'gan'
  l1_pixel_loss_weight: 10.0
  # Perceptual Loss
  perceptual_loss_weight: 100.0
eval:
  facenet:
    deprocess_and_preprocess: True
    crop_faces: True
